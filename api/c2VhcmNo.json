[{"title":"third","date":"2020-05-29T02:37:09.000Z","date_formatted":{"ll":"2020年5月29日","L":"2020/05/29","MM-DD":"05-29"},"updated":"2020-05-29T02:38:16.000Z","content":"这样可以发图吗\n\n","plink":"https://vichin0215.github.io/year/05/29/third/"},{"title":"有日期了吗","date":"2020-05-29T02:02:17.000Z","date_formatted":{"ll":"2020年5月29日","L":"2020/05/29","MM-DD":"05-29"},"updated":"2020-05-29T02:05:34.824Z","content":"This is a test.\n\n","thumbnail":"year/05/29/second/blue.jpg","color":"#111","plink":"https://vichin0215.github.io/year/05/29/second/"},{"title":"我的第一篇博客文章","date":"2020-05-28T13:40:00.000Z","date_formatted":{"ll":"2020年5月28日","L":"2020/05/28","MM-DD":"05-28"},"updated":"2020-05-29T01:52:59.955Z","content":"  花费了很长时间终于基本建好了这个还不太完美的博客。\n  由于自己能力有限，还有很多想要的功能不懂怎么实现。熊宁总说，博客的内容才是最重要的，但我就是那种一做就一定要做得很完美的性格，不然心里总觉得不舒畅不舒服（包括现在也有点哈哈哈）。想想自己确实还什么也不懂，有的方法别人已经写出来了可是我还是不理解、做不对，或许现在确实不必太过纠结。\n  今天在群里问了一个问题，因为我的图片上传不了，我不知道是什么原因。后来群里有两个人告诉我问题是什么什么，可我居然听不懂，所以又问了一遍具体应该怎么做。这时有位群友告诉了我做法，还建议我使用图床会更好，后来问题解决了。在这其间有个人说了一句：“这基础也太差了”，虽然他刚发就马上撤了回去，但我还是看到了。那时候心里其实还挺不舒服的吧，刚想要解释一下，后来又觉得好像也没有必要了。我现在的确还什么也不懂啊，我问的东西可能在他们眼里是很低级、很弱智的问题吧，但是我自己却找不出原因也理解不了。过了一会，当时告诉我做法的群友私聊了问我不是计算机专业的吧？突然好像心里的委屈有了发泄口，我赶紧回答是啊，我还没学过这方面的知识，然后他就说他也是业余的，他是学新闻的，花了半年多边做边学才搞懂，还给我分享了他的博客。（哈哈其实我想要的很多功能他都有，但是我觉得全都问人家好像太打扰别人了，默默羡慕……）\n  其实有时候我也会想，我是不是特别笨，或者说学习能力很弱，我是不是不适合学这个做这个呢，计算机真的适合我吗？我总觉得自己学知识很慢，好像别人理解能力都很强，新的知识很快就能掌握了。这个疑问似乎很早就出现了，我之所以有的成绩出色是因为我花费了更多的精力和时间，而不是因为我学的好，所谓学的好我认为应该是学的快、理解掌握的快。而我不属于那类人，可能我本来就是那种比较笨的。\n  总而言之，目前就先这样吧，后续的摸索中等我搞明白了再慢慢完善。现在才刚刚开始，我还有好长好长的路要走啊……\n","thumbnail":"year/05/28/first-blog/sunset.jpg","color":"#111","plink":"https://vichin0215.github.io/year/05/28/first-blog/"},{"title":"第三篇","date":"2020-04-10T07:25:58.000Z","date_formatted":{"ll":"2020年4月10日","L":"2020/04/10","MM-DD":"04-10"},"updated":"2020-04-10T07:36:53.331Z","content":"哈喽哈喽\n","thumbnail":"year/04/10/第三篇/tree.jpg","color":"#111","plink":"https://vichin0215.github.io/year/04/10/第三篇/"},{"title":"go语言搭建pipeline","date":"2020-04-02T03:27:33.000Z","date_formatted":{"ll":"2020年4月2日","L":"2020/04/02","MM-DD":"04-02"},"updated":"2020-04-09T01:05:29.185Z","content":"pipeline有个数据源，把这个数据源送到一个节点，这个节点处理完再送到下一个节点，这样一级一级送下去，最后又一个Sink，Sink节点只进不出。\n节点和节点之间怎么通信呢？\n传统语言是通过方法调用实现的。\nGo语言是通过channel通信的\n归并排序数据分为左右两半，分别归并排序，再把两个有序数据合并\n外部排序pipeline首先有个原始数据，然后分块得读取这个原始数据，保证内存能够放得下，每一块各自进行内部排序，排好序后两两进行归并，每个归并节点放的都是排好序的大数据，然后再两两归并，最后写入文件中。\n\n实现基础节点首先我们有一个数据源，它返回的是一个channel\n12345678910func ArraySource(a ...int) &lt;-chan int &#123;\tout := make(chan int)\tgo func() &#123;\t\tfor _, v := range a &#123;\t\t\tout &lt;- v\t\t&#125;\t\tclose(out)\t&#125;()\treturn out&#125;然后对这个数据源进行内部排序\n12345678910111213141516171819func InMenSort(in &lt;-chan int) &lt;-chan int &#123;\tout := make(chan int)\tgo func() &#123;\t\t// Read into memory\t\ta := []int&#123;&#125;\t\tfor v := range in &#123;\t\t\ta = append(a, v)\t\t&#125;\t\t// Sort\t\tsort.Ints(a)\t\t//Output\t\tfor _, v := range a &#123;\t\t\tout &lt;- v\t\t&#125;\t\tclose(out)\t&#125;()\treturn out&#125;主函数直接拼接起来\n123456789101112131415package mainimport (\t\"fmt\"\t\"pipeline/pipeline\")func main() &#123;\tp := pipeline.InMenSort(pipeline.ArraySource(3, 2, 6, 7, 4))\t// 用range发送方一定要close\tfor v := range p &#123;\t\tfmt.Println(v)\t&#125;&#125;这样我们就实现了一个基础的内部排序了！\n归并节点讲两个内部排序归并\n123456789101112131415161718func Merge(in1, in2 &lt;-chan int) &lt;-chan int &#123;    out := make(chan int)    go func() &#123;      v1, ok1 := &lt;-in1      v2, ok2 := &lt;-in2      for ok1 || ok2 &#123;        if !ok2 || (ok1 &amp;&amp; v1 &lt;= v2) &#123;          out &lt;- v1          v1, ok1 = &lt;-in1        &#125; else &#123;          out &lt;- v2          v2, ok2 = &lt;-in2        &#125;      &#125;      close(out)    &#125;()    return out&#125;主函数merge两个内部排序节点\n1234567891011121314package mainimport (\t\"fmt\"\t\"pipeline/pipeline\")func main() &#123;\tp := pipeline.Merge(pipeline.InMenSort(pipeline.ArraySource(3, 2, 6, 7, 4)),pipeline.InMenSort(pipeline.ArraySource(1, 2, 9, 5, 3)))\t// 用range发送方一定要close\tfor v := range p &#123;\t\tfmt.Println(v)\t&#125;&#125;现在我们已经实现了从array读取数据源，然后用两个内部排序节点排序，最后再通过merge将两个节点归并。\n我们的数据源是从array读取，这点不好，让我们来从文件中读取吧！\n文件读写在外部排序中数据源要是一个文件\n读文件，这里统一用大端BigEndian读取数据\n12345678910111213141516171819func ReaderSource(reader io.Reader) &lt;-chan int &#123;\tout := make(chan int)\tgo func() &#123;\t\tbuffer := make([]byte, 8)\t\tfor &#123;\t\t\tn, err := reader.Read(buffer)\t\t\tif n &gt; 0 &#123;\t\t\t\t// 把[]byte转化为int\t\t\t\tv := int(binary.BigEndian.Uint64(buffer))\t\t\t\tout &lt;- v\t\t\t&#125;\t\t\tif err != nil &#123;\t\t\t\tbreak\t\t\t&#125;\t\t&#125;\t\tclose(out)\t&#125;()\treturn out&#125;写文件\n1234567func WriterSink(writer io.Writer, in &lt;-chan int) &#123;\tfor v := range in &#123;\t\tbuffer := make([]byte, 8)\t\tbinary.BigEndian.PutUint64(buffer, uint64(v))\t\twriter.Write(buffer)\t&#125;&#125;当然数据源应该是自动产生的，我们再实现一个随机产生数据源的方法\n123456789func RandomSource(count int) &lt;-chan int &#123;\tout := make(chan int)\tgo func() &#123;\t\tfor i := 0; i &lt; count; i++ &#123;\t\t\tout &lt;- rand.Int()\t\t&#125;\t&#125;()\treturn out&#125;我们的main函数如下\n1234567891011121314151617181920212223242526func main() &#123;\tconst filename = \"large.in\"\tconst n = 100000000\tfile, err := os.Create(filename)\tif err != nil &#123;\t\tpanic(err)\t&#125;\tdefer file.Close()\tp := pipeline.RandomSource(n)\tpipeline.WriterSink(file, p)\tfile, err = os.Open(filename)\tif err != nil &#123;\t\tpanic(err)\t&#125;\tdefer file.Close()\tp = pipeline.ReaderSource(file)\tcount := 0\tfor v := range p &#123;\t\tfmt.Println(v)\t\tcount++\t\tif count &gt;= 100 &#123;\t\t\tbreak\t\t&#125;\t&#125;&#125;这就实现了自动生成随机数，并写入文件\n但是上面这段代码是大数据，一共产生100兆个数，速度很慢，为什么这么慢呢？\n因为Reader和Writer没有buffer\n我们再给Reader和Writer加个buffer\n12345678910111213141516171819202122232425262728293031func main() &#123;    const filename = \"large.in\"    const n = 100000000    file, err := os.Create(filename)    if err != nil &#123;      \tpanic(err)    &#125;    defer file.Close()    p := pipeline.RandomSource(n)    writer := bufio.NewWriter(file)    pipeline.WriterSink(writer, p)    writer.Flush()    file, err = os.Open(filename)    if err != nil &#123;      \tpanic(err)    &#125;    defer file.Close()    reader := bufio.NewReader(file)    p = pipeline.ReaderSource(reader)    count := 0    for v := range p &#123;      fmt.Println(v)      count++      if count &gt;= 100 &#123;          break        &#125;    &#125;&#125;buffer的writer要记得flush，不然得到的数据就不是800兆了。\n现在我们实现了更多的节点，有ReaderSource和WriterSink，我们又用随机数演示测试数据的生成，都用bufio包装了，所以速度很快\n完整外部排序现在我们这个外部排序pipeline还有一些没有完成，一个是读取文件要分块读取，还有两两归并再归并还没有实现\n现在我们来实现这些功能吧！\n首先我们来实现多路的两两归并\n123456789func MergeN(inputs ...&lt;-chan int) &lt;-chan int &#123;    if len(inputs) == 1 &#123;      return inputs[0]    &#125;    m := len(inputs) / 2    // merge inputs[0..m) and inputs[m..end)    return Merge(MergeN(inputs[:m]...), MergeN(inputs[m:]...))&#125;看起来很简单啊，只是用递归去实现了一下\n然后我们reader读文件要分块\n那我们来改造一下ReaderSource\n123456789101112131415161718192021func ReaderSource(reader io.Reader, chunkSize int) &lt;-chan int &#123;\tout := make(chan int)\tgo func() &#123;      buffer := make([]byte, 8)      bytesRead := 0      for &#123;          n, err := reader.Read(buffer)          bytesRead += n          if n &gt; 0 &#123;              // 把[]byte转化为int              v := int(binary.BigEndian.Uint64(buffer))              out &lt;- v          &#125;          if err != nil || (chunkSize != -1 &amp;&amp; bytesRead &gt;= chunkSize) &#123;              break          &#125;      &#125;      close(out)\t&#125;()\treturn out&#125;这里我们设置chunkSize为-1表示全部读，否则就是不能超过chunkSize读取\n很简单吧！现在我们开始实现外部排序吧！\n首先我们来创建一个pipeline\n123456789101112131415161718func createPipeline(filename string, fileSize, chunkCount int) &lt;-chan int &#123;    chunkSize := fileSize / chunkCount    sortResults := []&lt;-chan int&#123;&#125;    for i := 0; i &lt; chunkCount; i++ &#123;        file, err := os.Open(filename)        if err != nil &#123;          \tpanic(err)        &#125;        // file要从这一块开始读，所以file要移动一下        file.Seek(int64(chunkSize * i), 0)        source := pipeline.ReaderSource(bufio.NewReader(file), chunkSize)        sortResults= append(sortResults, pipeline.InMenSort(source))    &#125;    return pipeline.MergeN(sortResults...)&#125;这里我们分块去读，每次读file都移动一下，然后排好序，把结果merge起来。\n接下来我们把排好序的数据写入文件\n123456789101112func writeToFile(p &lt;-chan int, filename string) &#123;    file, err := os.Create(filename)    if err != nil &#123;      \tpanic(err)    &#125;    defer file.Close()    writer := bufio.NewWriter(file)    defer writer.Flush()    pipeline.WriterSink(writer, p)&#125;然后再打印出来\n123456789101112func printFile(filename string) &#123;    file, err := os.Open(filename)    if err != nil &#123;      \tpanic(err)    &#125;    defer file.Close()    p := pipeline.ReaderSource(file, -1)    for v := range p &#123;      \tfmt.Println(v)    &#125;&#125;最后主函数这样写\n12345func main() &#123;    p := createPipeline(\"small.in\", 512, 4)    writeToFile(p, \"small.out\")    printFile(\"small.out\")&#125;但是程序还是很慢，排序需要跑将近30秒，我们看慢在哪里，channel是无缓存的，这样就会阻塞等待，所以我们给channel加个1024的缓存。\n虽然排序是并行的排的，但是merge是O(n)的，每个数都要过一下。所以时间比非并行的要慢。\n我们来看一下输出结果：\n\n很好！\n网络版外部排序InMemSort和WriterSink之间通过网络连接，ReaderSource和Merge之间通过网络连接\n首先我们把服务器搭起来\n1234567891011121314151617181920func NetWorkSink(addr string, in &lt;-chan int) &#123;    listener, err := net.Listen(\"tcp\", addr)    if err != nil &#123;      \tpanic(err)    &#125;    go func() &#123;      defer listener.Close()      conn, err := listener.Accept()      if err != nil &#123;        \tpanic(err)      &#125;      defer conn.Close()      writer := bufio.NewWriter(conn)      defer writer.Flush()      WriterSink(writer, in)    &#125;()&#125;然后封装一下客户端\n12345678910111213141516func NetworkSource(addr string) &lt;-chan int &#123;    out := make(chan int)    go func() &#123;        conn, err := net.Dial(\"tcp\", addr)        if err != nil &#123;          \tpanic(err)        &#125;        r := ReaderSource(bufio.NewReader(conn), -1)        for v := range r &#123;          \tout &lt;- v        &#125;        close(out)    &#125;()    return out&#125;然后我们再把createPipeline封装成network版\n1234567891011121314151617181920212223242526func createNetworkPipeline(filename string, fileSize, chunkCount int) &lt;-chan int &#123;    chunkSize := fileSize / chunkCount    pipeline.Init()    sortAddr := []string&#123;&#125;    for i := 0; i &lt; chunkCount; i++ &#123;        file, err := os.Open(filename)        if err != nil &#123;          \tpanic(err)      &#125;      // file要从这一块开始读，所以file要移动一下      file.Seek(int64(chunkSize * i), 0)      source := pipeline.ReaderSource(bufio.NewReader(file), chunkSize)      addr := \":\" + strconv.Itoa(7000 + i)      pipeline.NetWorkSink(addr, pipeline.InMenSort(source))      sortAddr = append(sortAddr, addr)    &#125;    sortResults := []&lt;-chan int&#123;&#125;    for _, addr := range sortAddr &#123;      \tsortResults = append(sortResults, pipeline.NetworkSource(addr))    &#125;    return pipeline.MergeN(sortResults...)&#125;这样就可以部署到服务器上了\n好了，用go语言搭建并行处理管道已经完成了！\n","plink":"https://vichin0215.github.io/year/04/02/我的第一篇文章/"},{"title":"试试能不能发","date":"2020-04-02T03:27:33.000Z","date_formatted":{"ll":"2020年4月2日","L":"2020/04/02","MM-DD":"04-02"},"updated":"2020-05-28T15:01:33.476Z","content":"这是可爱清清的第二篇文章呀\n嘻嘻\n嘿嘿哈哈哈哈哈哈哈\n(#^.^#)\n\n你好呀\n","plink":"https://vichin0215.github.io/year/04/02/我的第二篇文章/"},{"title":"About Me","date":"1999-11-07T12:46:25.000Z","date_formatted":{"ll":"1999年11月7日","L":"1999/11/07","MM-DD":"11-07"},"updated":"2020-05-28T11:05:16.379Z","content":"hi\n\n","plink":"https://vichin0215.github.io/about/"}]